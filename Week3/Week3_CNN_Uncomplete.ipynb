{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5915a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378af80b",
   "metadata": {},
   "source": [
    "# 1 - Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b6439",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Size:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Test Size:\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "idx = np.random.randint(low= 0, high=50000)\n",
    "plt.imshow(x_train[idx])\n",
    "plt.title(label_names[int(y_train[idx])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c8d29",
   "metadata": {},
   "source": [
    "# 2- Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e118aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train/255.0\n",
    "X_test = x_test/255.0\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(np.squeeze(y_train), 10)\n",
    "Y_test = tf.keras.utils.to_categorical(np.squeeze(y_test), 10)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7cde2",
   "metadata": {},
   "source": [
    "# 3- Model development\n",
    "Conv Layers:\n",
    "\n",
    "1- 32 filter 3x3 + relu\n",
    "\n",
    "2- 32 filter 3x3 + relu\n",
    "\n",
    "3- max pooling 2x2\n",
    "\n",
    "4- 64 filter 3x3 + relu\n",
    "\n",
    "5- 64 filter 3x3 + relu\n",
    "\n",
    "6- max pooling 2x2\n",
    "\n",
    "7- 128 filter 3x3 + relu\n",
    "\n",
    "8- 128 filter 3x3 + relu\n",
    "\n",
    "# Classification Head\n",
    "\n",
    "9- Flattening\n",
    "\n",
    "10- Dense 128\n",
    "\n",
    "11: dense 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(...)\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb8f38",
   "metadata": {},
   "source": [
    "## Set cost- evaluation metric- optimizer\n",
    "    - set otimizer to adam with learning rate 1e-3\n",
    "    - set appropriate loss\n",
    "    - set appropriate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86631eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=...,\n",
    "              loss=...,\n",
    "              metrics=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f6673",
   "metadata": {},
   "source": [
    "# 4- Triain model\n",
    "    - set batch_size to 32\n",
    "    - set the validation set to 10% of training data\n",
    "    - train for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26984f",
   "metadata": {},
   "source": [
    "## Analyze training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1)\n",
    "axs[0].plot(hist.history['loss'])\n",
    "axs[0].plot(hist.history['val_loss'])\n",
    "\n",
    "axs[1].plot(hist.history['categorical_accuracy'])\n",
    "axs[1].plot(hist.history['val_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296b498",
   "metadata": {},
   "source": [
    "# 5- Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed912001",
   "metadata": {},
   "source": [
    "#  ============== Use Data Augmentation =============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24533da8",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "    - use ImageDataGenerator from tensorflow.keras.preprocessing.image\n",
    "    - create an object from ImageDataGenerator with validation_split=0.2 and \n",
    "        - rotation_range=20,\n",
    "        - width_shift_range=0.2\n",
    "        - height_shift_range=0.2\n",
    "        - horizontal_flip=True\n",
    "     - fit the data_gen_train to taining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_gen_train = ...\n",
    "\n",
    "# img_it = data_gen_train.flow(X_train, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2ca63",
   "metadata": {},
   "source": [
    "# Create another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_augmentation = create_model()\n",
    "model_with_augmentation.compile(optimizer=...,\n",
    "                                loss=...,\n",
    "                                metrics=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118d0d4",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12da992",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_with_augmentation.fit(data_gen_train.flow(X_train, Y_train, batch_size=32,subset='training'),\n",
    "                                   validation_data=data_gen_train.flow(X_train, Y_train,batch_size=32, subset='validation'),\n",
    "                                   epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc52f8",
   "metadata": {},
   "source": [
    "# Training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1)\n",
    "axs[0].plot(hist.history['loss'])\n",
    "axs[0].plot(hist.history['val_loss'])\n",
    "\n",
    "axs[1].plot(hist.history['categorical_accuracy'])\n",
    "axs[1].plot(hist.history['val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df3caa",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf97a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f86b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
